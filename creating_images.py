# -*- coding: utf-8 -*-
"""Creating Images

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GWB1TRzV13cq2NmOJxfkhkopGPNf-_kK
"""

# Commented out IPython magic to ensure Python compatibility.
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.preprocessing import image
import numpy as np
import pandas as pd
from tqdm import tqdm
from keras.applications.vgg16 import VGG16
import cv2
import math
import os
from glob import glob
from scipy import stats as s 
from PIL import Image
from sklearn.metrics import accuracy_score


import PIL

from google.colab import files
uploaded = files.upload()


import cv2     # for capturing videos
import math   # for mathematical operations
import matplotlib.pyplot as plt    # for plotting the images
# %matplotlib inline
import pandas as pd
from keras.preprocessing import image   # for preprocessing the images
import numpy as np    # for mathematical operations
from keras.utils import np_utils
from skimage.transform import resize   # for resizing images
from sklearn.model_selection import train_test_split
from glob import glob
from tqdm import tqdm



test = []
train = []

te = 0

arr = os.listdir("/content/")
#print(arr)
for i in range (len(arr)-1):
  if (arr[i] == '.config'):
    arr.remove('.config')
for i in range (len(arr)):
  if(arr[i] == 'sample_data'):
    arr.remove('sample_data')
for i in range (len(arr)-1):
  if(arr[i] == 'train_1'):
    arr.remove('train_1')
for i in range (len(arr)-1):
  if(arr[i] == '.ipynb_checkpoints'):
    arr.remove('.ipynb_checkpoints')


index = arr[0].find("-")
word = arr[0][0:index]
print(arr)
for a in range(0, len(arr)):
  if(te <= 1):
    train.append(arr[a])
    te = te + 1
  elif(te == 2):
    test.append(arr[a])
    te = te + 1
  elif(te == 3):
    test.append(arr[a])
    te = 0


for i in range(len(train)-1):
  if(train[i] == "test_1"):
    train.remove("test_1")
print("train", train)
print("test", test)

for i in range(0, len(train)):
    count = 0
    videoFile = "/content/" + train[i]
    cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path
    #frameRate = cap.get(5) #frame rate
    x=1
    while(cap.isOpened()):
        frameId = cap.get(1) #current frame number
        ret, frame = cap.read()
        if (ret != True):
            break
        # storing the frames in a new folder named train_1
        #filename ='train_1/' + train[i] +"_frame%d.jpg" % count;count+=1
        filename ='train_1/' + train[i] +"_frame" + "{0:0=2d}".format(count) + ".jpg"
        
        count+=1
        cv2.imwrite(filename, frame)
    cap.release()

for i in range(0, len(test)):
    count = 0
    videoFile = "/content/" + test[i]
    cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path
    #frameRate = cap.get(5) #frame rate
    x=1
    while(cap.isOpened()):
        frameId = cap.get(1) #current frame number
        ret, frame = cap.read()
        if (ret != True):
            break
        # storing the frames in a new folder named train_1
        #filename ='test_1/' + test[i] +"_frame%d.jpg" % count;count+=1
        filename ='test_1/' + test[i] +"_frame" + "{0:0=2d}".format(count) + ".jpg"
        count+=1
        cv2.imwrite(filename, frame)
    cap.release()


# creating an empty list
train_image = []
tarr = os.listdir("train_1/")

from numpy import asarray


# for loop to read and store frames
#print("len ", len(tarr))
for i in range(len(tarr)):
    # loading the image and keeping the target size as (224,224,3)
    if(tarr[i].endswith(".jpg")):
      img = cv2.imread('train_1/'+tarr[i])
      img = cv2.resize(img, (224,224))
      #print("tarr", tarr[i])
      assert(img is not None)
      pixels = asarray(img)
      # # converting it to array
      # img = image.img_to_array(img)
      # normalizing the pixel value
      img = pixels.astype('float32')
      img = img/255
      # appending the image to the train_image list
      train_image.append(img)
      #print ("train ", train_image)


#print ("train ", train_image)
# converting the list to numpy array
#X = np.array(train_image)
#X = train_image
# Susan says: could try this:
X = np.stack(train_image)


# shape of the array
#print("type of X:", type(X))
#print("x shape", X.shape)

y = []
for i in range(len(tarr)):
  if(tarr[i].endswith(".jpg")):
    index = tarr[i].find("-")
    y.append(tarr[i][0:index])

#print(y)
#print(len(y))
#X = np.asarray(X).astype(np.float32)
#X = np.array(X, dtype=object)
#y = np.asarray(y)


# creating the training and validation set
#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)
#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2 )
#print("xtrain[0] shape", X_train[0].shape)

# print("ytest", y_test)

# print("ytrain", y_train)
# y_train = pd.get_dummies(y_train)
# y_test = pd.get_dummies(y_test)

# base_model = VGG16(weights='imagenet', include_top=True)

# # extracting features for training frames

# #print("dtype ",X_train[0].dtype)

# X_train = base_model.predict(X_train)


# # extracting features for validation frames
# X_test = base_model.predict(X_test)
# X_test.shape




# model = Sequential()
# model.add(Dense(1024, activation='relu', input_shape=(25088,)))
# model.add(Dropout(0.5))
# model.add(Dense(512, activation='relu'))
# model.add(Dropout(0.5))
# model.add(Dense(256, activation='relu'))
# model.add(Dropout(0.5))
# model.add(Dense(128, activation='relu'))
# model.add(Dropout(0.5))
# model.add(Dense(101, activation='softmax'))

# #model.summary()

# # compiling the model
# model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])


# #stack,hstack, vstack