{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "77u8az88IN6A"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "from glob import glob\n",
        "from scipy import stats as s\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "import PIL\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "arr = os.listdir(\"/content/\")\n",
        "num = len(os.listdir(\"/content/sample_data/\")) + len(os.listdir(\"/content/temp/\"))\n",
        "+ len(os.listdir(\"/content/test_1/\")) + + len(os.listdir(\"/content/train_1/\"))\n",
        "\n",
        "numofvids = len(arr) - num - 1\n",
        "f = open(\"trainlist01.txt\",\"w+\")\n",
        "arr.sort()\n",
        "\n",
        "arrofvids = []\n",
        "for a in range (len(arr)):\n",
        "  if(arr[a].endswith(\".avi\")):\n",
        "    arrofvids.append(arr[a])\n",
        "\n",
        "for i in range (0,len(arrofvids)//2):\n",
        "  f.write(arrofvids[i] + \"\\n\")\n",
        "f.close()\n",
        "\n",
        "f = open(\"testlist01.txt\",\"w+\")\n",
        "for i in range (len(arrofvids)//2, len(arrofvids),1):\n",
        "  f.write(arrofvids[i] + \"\\n\")\n",
        "f.close()\n",
        "print(\"please read\", len(arrofvids))\n",
        "\n",
        "# open the .txt file which have names of training videos\n",
        "f = open(\"trainlist01.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating a dataframe having video names\n",
        "train = pd.DataFrame()\n",
        "train['video_name'] = videos\n",
        "train = train[:-1]\n",
        "train.head()\n",
        "\n",
        "train_video_tag = []\n",
        "for i in range(train.shape[0]):\n",
        "    index = train['video_name'][i].find(\"-\")\n",
        "    train_video_tag.append(train['video_name'][i][:index])\n",
        "train['tag'] = train_video_tag\n",
        "\n",
        "\n",
        "# open the .txt file which have names of training videos\n",
        "f = open(\"testlist01.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating a dataframe having video names\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test.head()\n",
        "\n",
        "\n",
        "# creating tags for test videos\n",
        "test_video_tag = []\n",
        "for i in range(test.shape[0]):\n",
        "    test_video_tag.append(test['video_name'][i][:index])\n",
        "test['tag'] = test_video_tag\n",
        "\n",
        "# storing the frames from training videos\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    count = 0\n",
        "    videoFile = train['video_name'][i]\n",
        "    cap = cv2.VideoCapture('/content/'+videoFile)   # capturing the video from the given path\n",
        "    frameRate = cap.get(5) #frame rate\n",
        "    x=1\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "            # storing the frames in a new folder named train_1\n",
        "            filename ='train_1/' + videoFile.split('-')[0]+\"_frame%d.jpg\" % count;count+=1\n",
        "            cv2.imwrite(filename, frame)\n",
        "    cap.release()\n",
        "\n",
        "totallist = os.listdir(\"/content/train_1/\")\n",
        "print(\"this is total lenght of train\", len(totallist))\n",
        "\n",
        "# getting the names of all the images\n",
        "images = glob(\"train_1/*.jpg\")\n",
        "train_image = []\n",
        "train_class = []\n",
        "for i in tqdm(range(len(images))):\n",
        "    # creating the image name\n",
        "    train_image.append(images[i].split('/')[1])\n",
        "    # creating the class of image\n",
        "    train_class.append(images[i].split('/')[1].split('_')[0])\n",
        "\n",
        "# storing the images and their class in a dataframe\n",
        "train_data = pd.DataFrame()\n",
        "train_data['image'] = train_image\n",
        "train_data['class'] = train_class\n",
        "\n",
        "# converting the dataframe into csv file\n",
        "train_data.to_csv('/content/train_new.csv',header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30ehHUvTIR-Q"
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train = pd.read_csv('/content/train_new.csv')\n",
        "train.head()\n",
        "\n",
        "\n",
        "# creating an empty list\n",
        "train_image = []\n",
        "\n",
        "# for loop to read and store frames\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    # loading the image and keeping the target size as (224,224,3)\n",
        "    img = image.load_img('train_1/'+train['image'][i], target_size=(224,224,3))\n",
        "    # converting it to array\n",
        "    img = image.img_to_array(img)\n",
        "    # normalizing the pixel value\n",
        "    img = img/255\n",
        "    # appending the image to the train_image list\n",
        "    train_image.append(img)\n",
        "\n",
        "# converting the list to numpy array\n",
        "X = np.array(train_image)\n",
        "#X = np.stack(train_image)\n",
        "\n",
        "# shape of the array\n",
        "X.shape\n",
        "\n",
        "# separating the target\n",
        "y = train['class']\n",
        "\n",
        "print(\"type.  \", type(y))\n",
        "\n",
        "\n",
        "print(\"this is y \", y)\n",
        "\n",
        "# creating the training and validation set\n",
        "print(\"length of train\", len(X))\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,stratify = y)\n",
        "print(\"hi\", len(X))\n",
        "print(len(y))\n",
        "X_train = X[:len(X)//2]\n",
        "X_test = X[len(X)//2:]\n",
        "y_train = y[:len(y)//2]\n",
        "y_test = y[len(y)//2:]\n",
        "\n",
        "# creating dummies of target variable for train and validation set\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n",
        "\n",
        "print(y_train.columns)\n",
        "print(y_test.columns)\n",
        "# import keras\n",
        "# import keras.utils\n",
        "# from keras import utils as utils\n",
        "# from keras.utils import to_categorical\n",
        "# import tensorflow as tf\n",
        "# y_train = tf.keras.utils.to_categorical(y_train, 7)\n",
        "# y_test = tf.keras.utils.to_categorical(y_test, 7)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "# creating the base model of pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "# extracting features for training frames\n",
        "X_train = base_model.predict(X_train)\n",
        "X_train.shape\n",
        "\n",
        "\n",
        "# extracting features for validation frames\n",
        "X_test = base_model.predict(X_test)\n",
        "X_test.shape\n",
        "\n",
        "print(X_test.shape)\n",
        "print(X_train.shape)\n",
        "\n",
        "# reshaping the training as well as validation frames in single dimension\n",
        "X_train = X_train.reshape(38, 7*7*512)\n",
        "X_test = X_test.reshape(38, 7*7*512) #first num of shape\n",
        "\n",
        "\n",
        "# normalizing the pixel values\n",
        "max = X_train.max()\n",
        "X_train = X_train/max\n",
        "X_test = X_test/max\n",
        "\n",
        "\n",
        "\n",
        "# shape of images\n",
        "X_train.shape\n",
        "\n",
        "\n",
        "\n",
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "#model.add(Dense(101, activation='softmax'))\n",
        "model.add(Dense(24, activation='softmax')) #last num of shape\n",
        "\n",
        "# tf.keras.utils.to_categorical(\n",
        "#     y_train, num_classes=None, dtype='float32'\n",
        "# )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yae4FD9IIVhy"
      },
      "source": [
        "# defining a function to save the weights of best model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp_save = ModelCheckpoint('imagenet', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# compiling the model\n",
        "#model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "#model.add( keras.layers.Flatten())\n",
        "\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as utils\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# y_train = tf.reshape(y_train, (-1, 1))\n",
        "# y_test = tf.reshape(y_test, (-1, 1))\n",
        "# y_train = tf.reshape(y_train, [7,4])\n",
        "# y_test = tf.reshape(y_test, [2,2])\n",
        "\n",
        "\n",
        "# print(y_train.shape)\n",
        "# print(y_test.shape)\n",
        "\n",
        "# y_train = to_categorical(y_train, 4)\n",
        "# y_test = to_categorical(y_test, 4)\n",
        "\n",
        "#to_categorical(y_train, num_classes=None, dtype='float32')\n",
        "print(\"y_train\", y_train.shape)\n",
        "print(\"y_test\", y_test.shape)\n",
        "print(\"X_train\", X_train.shape)\n",
        "print(\"X_test\", X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "# training the model\n",
        "#model.fit(X_train, y_train, batch_size=128, epochs=200, validation_data=(X_test, y_test))\n",
        "#model.fit(X_train, y_train, batch_size=128, epochs=2, validation_data=(X_test, y_test))\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZMaKApDIWnG"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "from glob import glob\n",
        "from scipy import stats as s\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(24, activation='softmax')) #last num\n",
        "\n",
        "\n",
        "# loading the trained weights\n",
        "#model.load_weights(\"weights.hdf5\")\n",
        "\n",
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "\n",
        "# getting the test list\n",
        "f = open(\"testlist01.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating the dataframe\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test_videos = test['video_name']\n",
        "test.head()\n",
        "\n",
        "# creating the tags\n",
        "train = pd.read_csv('/content/train_new.csv')\n",
        "y = train['class']\n",
        "\n",
        "y = pd.get_dummies(y)\n",
        "\n",
        "# creating two lists to store predicted and actual tags\n",
        "predict = []\n",
        "actual = []\n",
        "# for loop to extract frames from each test video\n",
        "for i in tqdm(range(test_videos.shape[0])):\n",
        "    count = 0\n",
        "    videoFile = test_videos[i]\n",
        "    cap = cv2.VideoCapture('/content/'+videoFile)   # capturing the video from the given path\n",
        "    frameRate = cap.get(5) #frame rate\n",
        "    x=1\n",
        "    # removing all other files from the temp folder\n",
        "    files = glob('temp/*')\n",
        "    for f in files:\n",
        "        os.remove(f)\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "            # storing the frames of this particular video in temp folder\n",
        "            filename ='temp/' + \"_frame%d.jpg\" % count;count+=1\n",
        "            cv2.imwrite(filename, frame)\n",
        "    cap.release()\n",
        "\n",
        "    # reading all the frames from temp folder\n",
        "    images = glob(\"temp/*.jpg\")\n",
        "\n",
        "    prediction_images = []\n",
        "    for i in range(len(images)):\n",
        "        img = image.load_img(images[i], target_size=(224,224,3))\n",
        "        img = image.img_to_array(img)\n",
        "        img = img/255\n",
        "        prediction_images.append(img)\n",
        "\n",
        "    # converting all the frames for a test video into numpy array\n",
        "    prediction_images = np.array(prediction_images)\n",
        "    # extracting features using pre-trained model\n",
        "    prediction_images = base_model.predict(prediction_images)\n",
        "    # converting features in one dimensional array\n",
        "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
        "    # predicting tags for each array\n",
        "    prediction = model.predict_classes(prediction_images)\n",
        "    # appending the mode of predictions in predict list to assign the tag to the video\n",
        "    predict.append(y.columns.values[s.mode(prediction)[0][0]])\n",
        "    # appending the actual tag of the video\n",
        "    actual.append(videoFile.split(\"-\")[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktj1mQBEIZCD"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(predict, actual)*100"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}